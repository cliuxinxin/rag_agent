"""Streamlit å‰ç«¯å…¥å£ï¼šæ”¯æŒå¤šçŸ¥è¯†åº“ç®¡ç†ã€‚"""

import sys
import os
import streamlit as st
from dotenv import load_dotenv
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage, AIMessage

# æ·»åŠ  src è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from src.graph import graph
from src.utils import load_file, split_documents
from src.storage import save_kb, load_kbs, list_kbs, delete_kb, get_kb_details

load_dotenv()
st.set_page_config(page_title="DeepSeek RAG Supervisor", layout="wide")

# åˆå§‹åŒ– session state
if "messages" not in st.session_state:
    st.session_state.messages = []

if "selected_kbs" not in st.session_state:
    st.session_state.selected_kbs = []


def render_kb_management():
    st.header("ğŸ“‚ çŸ¥è¯†åº“ç®¡ç†")
    
    # === è¿™é‡Œå®šä¹‰äº†ä¸¤ä¸ª Tab ===
    tabs = st.tabs(["ğŸ“š çŸ¥è¯†åº“åˆ—è¡¨ & æ£€è§†", "â• æ–°å»º/è¿½åŠ çŸ¥è¯†"])
    
    # === Tab 1: åˆ—è¡¨ä¸æ£€è§† (ä½ ä¹‹å‰æ²¡çœ‹åˆ°çš„å¯èƒ½æ˜¯è¿™ä¸ª) ===
    with tabs[0]:
        existing_kbs = list_kbs()
        if not existing_kbs:
            st.info("æš‚æ— çŸ¥è¯†åº“ã€‚è¯·å»ç¬¬äºŒä¸ªæ ‡ç­¾é¡µæ–°å»ºã€‚")
        else:
            col_list, col_detail = st.columns([1, 2])
            with col_list:
                st.subheader("çŸ¥è¯†åº“åˆ—è¡¨")
                selected_kb_to_view = st.radio("é€‰æ‹©çŸ¥è¯†åº“æŸ¥çœ‹è¯¦æƒ…", existing_kbs)
                
                st.markdown("---")
                if st.button(f"ğŸ—‘ï¸ åˆ é™¤ {selected_kb_to_view}", type="primary"):
                    delete_kb(selected_kb_to_view)
                    st.success(f"å·²åˆ é™¤ {selected_kb_to_view}")
                    st.rerun()
            
            with col_detail:
                st.subheader(f"ğŸ” æ£€è§†: {selected_kb_to_view}")
                details = get_kb_details(selected_kb_to_view)
                
                m1, m2 = st.columns(2)
                m1.metric("ç‰‡æ®µæ•°é‡", details["doc_count"])
                m2.metric("æ€»å­—ç¬¦æ•°", details["total_chars"])
                
                st.divider()
                st.write("ğŸ“„ **å†…å®¹é¢„è§ˆ (éšæœºå‰5æ¡)**")
                if details["preview"]:
                    for item in details["preview"]:
                        with st.container(border=True):
                            st.caption(f"æ¥æº: {item['source']}")
                            st.text(item['content'])
                else:
                    st.write("è¯¥çŸ¥è¯†åº“ä¸ºç©ºæˆ–æ— æ³•è¯»å–ã€‚")

    # === Tab 2: æ–°å»º/è¿½åŠ  ===
    with tabs[1]:
        st.subheader("ä¸Šä¼ æ–‡æ¡£")
        kb_action = st.radio("æ¨¡å¼", ["è¿½åŠ åˆ°ç°æœ‰", "æ–°å»ºçŸ¥è¯†åº“"], horizontal=True)
        
        target_kb_name = ""
        if kb_action == "è¿½åŠ åˆ°ç°æœ‰":
            if existing_kbs:
                target_kb_name = st.selectbox("é€‰æ‹©ç›®æ ‡åº“", existing_kbs)
            else:
                st.warning("è¯·å…ˆæ–°å»º")
        else:
            target_kb_name = st.text_input("æ–°åº“åç§° (è‹±æ–‡/æ•°å­—)", placeholder="kb_v1")

        kb_language = st.selectbox("æ–‡æ¡£ä¸»è¦è¯­è¨€", ["Chinese", "English"], index=0)

        upload_mode = st.tabs(["ğŸ“ ä¸Šä¼ æ–‡ä»¶", "ğŸ“ ç²˜è´´æ–‡æœ¬"])
        raw_docs = []
        
        with upload_mode[0]:
            uploaded_files = st.file_uploader("æ”¯æŒ PDF/TXT", type=["pdf", "txt"], accept_multiple_files=True)
        
        with upload_mode[1]:
            text_input = st.text_area("è¾“å…¥æ–‡æœ¬", height=150)

        if st.button("ğŸ’¾ å¼€å§‹å¤„ç†å¹¶ä¿å­˜", use_container_width=True):
            if not target_kb_name:
                st.error("è¯·è¾“å…¥åç§°")
                return
                
            if uploaded_files:
                for f in uploaded_files:
                    raw_docs.extend(load_file(f))
            
            # å¤„ç†æ–‡æœ¬
            if text_input:
                raw_docs.append(Document(page_content=text_input, metadata={"source": "text_input"}))
            
            if not raw_docs:
                st.warning("æ²¡æœ‰æ£€æµ‹åˆ°è¾“å…¥å†…å®¹ã€‚")
                return

            # åˆ‡åˆ†å¹¶ä¿å­˜
            with st.spinner("æ­£åœ¨å¤„ç†..."):
                chunks = split_documents(raw_docs)
                
                # æ˜¾ç¤ºè¿›åº¦æ¡
                progress_bar = st.progress(0, text="å‡†å¤‡å‘é‡åŒ–...")
                
                # === ä¿®æ”¹ï¼šä¼ å…¥ selected language å’Œ progress bar ===
                save_kb(target_kb_name, chunks, language=kb_language, progress_bar=progress_bar)
                # ==================================
                
                st.success(f"æˆåŠŸå°† {len(chunks)} ä¸ªç‰‡æ®µå­˜å…¥çŸ¥è¯†åº“: [{target_kb_name}] (è¯­è¨€: {kb_language})")
                st.rerun()


def render_chat():
    """èŠå¤©ç•Œé¢åŠå¤„ç†é€»è¾‘ã€‚"""
    
    # --- ä¾§è¾¹æ ï¼šåœ¨èŠå¤©æ¨¡å¼ä¸‹æ˜¾ç¤ºçŸ¥è¯†åº“é€‰æ‹© ---
    # æ³¨æ„ï¼šStreamlit ä¼šæŒ‰é¡ºåºåœ¨ Sidebar è¿½åŠ å†…å®¹
    with st.sidebar:
        st.divider()
        st.subheader("ğŸ§  çŸ¥è¯†åº“é€‰æ‹©")
        all_kbs = list_kbs()
        selected_kbs = st.multiselect(
            "é€‰æ‹©è¦æ£€ç´¢çš„çŸ¥è¯†åº“", 
            all_kbs,
            default=all_kbs[0] if all_kbs else None
        )
        
        if not selected_kbs:
            st.warning("âš ï¸ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªçŸ¥è¯†åº“")
        else:
            st.success(f"å·²åŠ è½½ {len(selected_kbs)} ä¸ªåº“")
            
        st.session_state.selected_kbs = selected_kbs

    # --- ä¸»åŒºåŸŸï¼šèŠå¤©å†å² ---
    st.header("ğŸ’¬ æ™ºèƒ½é—®ç­”")

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # --- åº•éƒ¨ï¼šèŠå¤©è¾“å…¥æ¡† ---
    # è¿™é‡Œ st.chat_input æ˜¯åœ¨ä¸»å±‚çº§è°ƒç”¨çš„ï¼Œæ²¡æœ‰åµŒå¥—åœ¨ Tabs é‡Œï¼Œå› æ­¤ä¸ä¼šæŠ¥é”™
    user_input = st.chat_input("è¯·è¾“å…¥é—®é¢˜...", key="chat_input")
    
    if user_input:
        selected_kbs = st.session_state.get("selected_kbs", [])
        
        if not selected_kbs:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ é€‰æ‹©çŸ¥è¯†åº“ï¼")
            return

        # 1. åŠ è½½é€‰ä¸­çš„çŸ¥è¯†åº“æ–‡æ¡£åˆ°å†…å­˜
        with st.spinner("æ­£åœ¨åŠ è½½çŸ¥è¯†åº“ç´¢å¼•..."):
            # load_kbs ç°åœ¨è¿”å›ä¸¤ä¸ªå€¼
            source_documents, vector_store = load_kbs(selected_kbs)

        # 2. æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # 3. åˆå§‹åŒ– Graph è¾“å…¥
        # å°†å†å²æ¶ˆæ¯è½¬æ¢ä¸º LangChain æ ¼å¼ï¼Œä»¥ä¾¿ Agent æ‹¥æœ‰å¤šè½®å¯¹è¯è®°å¿†
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œåªä¼ å½“å‰é—®é¢˜ä½œä¸ºèµ·å§‹ï¼Œå¦‚æœéœ€è¦å¤šè½®è®°å¿†ï¼Œéœ€ä» session_state.messages è½¬æ¢
        initial_state = {
            "messages": [HumanMessage(content=user_input)],
            "source_documents": source_documents,
            "vector_store": vector_store,  # ä¼ å…¥ VectorStore
            "next": "Supervisor", # é»˜è®¤å…¥å£
            "current_search_query": "",
            "final_evidence": [],
            # åˆå§‹åŒ–è®¡æ•°å™¨
            "loop_count": 0,
            
            # === æ–°å¢ï¼šåˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨ ===
            "attempted_searches": [],
            "failed_topics": []
        }

        with st.chat_message("assistant"):
            # åˆ›å»ºä¸€ä¸ªå®¹å™¨ç”¨äºæ˜¾ç¤ºå®æ—¶çš„æ€è€ƒè¿‡ç¨‹
            status_container = st.status("Supervisor æ­£åœ¨è°ƒåº¦...", expanded=True)
            final_answer = ""

            try:
                # === æ ¸å¿ƒä¿®æ”¹ï¼šå¢åŠ  recursion_limit é…ç½® ===
                # é»˜è®¤æ˜¯ 25ï¼Œæˆ‘ä»¬å¢åŠ åˆ° 50ï¼Œé…åˆä»£ç é‡Œçš„ MAX_LOOPS=6 é€»è¾‘åŒé‡ä¿é™©
                graph_config = {"recursion_limit": 50}
                
                # è¿è¡Œ Graph
                # stream_mode="updates" ä¼šè¿”å›æ¯ä¸ªèŠ‚ç‚¹æ›´æ–°çš„çŠ¶æ€
                for step in graph.stream(initial_state, config=graph_config):
                    for node_name, update in step.items():
                        
                        # --- Supervisor èŠ‚ç‚¹ ---
                        if node_name == "Supervisor":
                            next_node = update.get("next")
                            query = update.get("current_search_query")
                            loop = update.get("loop_count", 0)
                            
                            if next_node == "Searcher":
                                status_container.write(f"ğŸ”„ **ç¬¬ {loop} è½®æ€è€ƒ**: å‘ç°ç¼ºå£ï¼ŒæŒ‡æ´¾æœç´¢ `{query}`")
                            elif next_node == "Answerer":
                                status_container.write("âœ… **å†³ç­–**: ä¿¡æ¯å……è¶³ (æˆ–è¾¾åˆ°ä¸Šé™)ï¼Œå‡†å¤‡å›ç­”ã€‚")
                        
                        # --- Searcher èŠ‚ç‚¹ ---
                        elif node_name == "Searcher":
                            # Searcher è¿”å›çš„æ˜¯ AIMessage
                            if "messages" in update and update["messages"]:
                                msg = update["messages"][0]
                                if hasattr(msg, 'content'):
                                    content = msg.content
                                    status_container.write(f"ğŸ” Searcher æœç´¢ç»“æœ:")
                                    status_container.markdown(content)
                        
                        # --- Answerer èŠ‚ç‚¹ ---
                        elif node_name == "Answerer":
                            # Answerer è¿”å›çš„æ˜¯æœ€ç»ˆå›ç­”
                            if "messages" in update and update["messages"]:
                                msg = update["messages"][0]
                                if hasattr(msg, 'content'):
                                    final_answer = msg.content
                                    status_container.write("âœ… Answerer å·²ç”Ÿæˆæœ€ç»ˆå›ç­”")
                                    # ä¸å†åœ¨è¿™é‡Œæ˜¾ç¤ºæœ€ç»ˆå›ç­”ï¼Œé¿å…é‡å¤æ˜¾ç¤º
                                    # status_container.markdown(final_answer)
                        
                        # --- END ---
                        elif node_name == "__end__":
                            status_container.update(label="å›ç­”å®Œæˆ", state="complete", expanded=False)
                
                # æ˜¾ç¤ºæœ€ç»ˆå›ç­” (ä¿®å¤é‡å¤æ˜¾ç¤ºé—®é¢˜)
                if final_answer:
                    # åªåœ¨æœ€ç»ˆå›ç­”ä¸ä¸ºç©ºä¸”æœªåœ¨æµä¸­æ˜¾ç¤ºæ—¶æ‰æ˜¾ç¤º
                    # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨ status_container ä¸­æ˜¾ç¤ºè¿‡
                    if final_answer not in [msg.get("content", "") for msg in st.session_state.messages]:
                        st.markdown(final_answer)
                    st.session_state.messages.append({"role": "assistant", "content": final_answer})
                else:
                    st.warning("æœªèƒ½ç”Ÿæˆå›ç­”ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚")
            
            except Exception as e:
                status_container.update(label="å‘ç”Ÿé”™è¯¯", state="error")
                st.error(f"è¿è¡Œé”™è¯¯: {e}")


def main():
    if not os.getenv("DEEPSEEK_API_KEY"):
        st.warning("è¯·é…ç½® .env æ–‡ä»¶ä¸­çš„ DEEPSEEK_API_KEY")

    # --- ä½¿ç”¨ä¾§è¾¹æ è¿›è¡Œé¡µé¢å¯¼èˆª ---
    with st.sidebar:
        st.title("DeepSeek RAG")
        page = st.radio(
            "åŠŸèƒ½å¯¼èˆª", 
            ["ğŸ’¬ å¯¹è¯æ¨¡å¼", "âš™ï¸ çŸ¥è¯†åº“ç®¡ç†"], 
            index=0
        )

    # æ ¹æ®é€‰æ‹©æ¸²æŸ“ä¸åŒçš„é¡µé¢ï¼ˆå‡½æ•°ï¼‰
    if page == "ğŸ’¬ å¯¹è¯æ¨¡å¼":
        render_chat()
    elif page == "âš™ï¸ çŸ¥è¯†åº“ç®¡ç†":
        render_kb_management()


if __name__ == "__main__":
    main()