"""Streamlit å‰ç«¯å…¥å£ï¼šæ”¯æŒå¤šçŸ¥è¯†åº“ç®¡ç†ã€‚"""

import sys
import os
import streamlit as st
from dotenv import load_dotenv
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage, AIMessage

# æ·»åŠ  src è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from src.graph import graph
from src.utils import load_file, split_documents
from src.storage import save_kb, load_kbs, list_kbs, delete_kb

load_dotenv()
st.set_page_config(page_title="DeepSeek RAG Supervisor", layout="wide")

# åˆå§‹åŒ– session state
if "messages" not in st.session_state:
    st.session_state.messages = []

if "selected_kbs" not in st.session_state:
    st.session_state.selected_kbs = []


def render_kb_management():
    """çŸ¥è¯†åº“ç®¡ç†ç•Œé¢ã€‚"""
    st.header("ğŸ“‚ çŸ¥è¯†åº“ç®¡ç†")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("ç°æœ‰çŸ¥è¯†åº“")
        existing_kbs = list_kbs()
        if not existing_kbs:
            st.info("æš‚æ— çŸ¥è¯†åº“ï¼Œè¯·åœ¨å³ä¾§åˆ›å»ºã€‚")
        
        for kb in existing_kbs:
            c1, c2 = st.columns([3, 1])
            c1.write(f"ğŸ“„ {kb}")
            if c2.button("åˆ é™¤", key=f"del_{kb}", type="primary"):
                delete_kb(kb)
                st.success(f"å·²åˆ é™¤çŸ¥è¯†åº“: {kb}")
                st.rerun()

    with col2:
        st.subheader("æ–°å»º / è¿½åŠ çŸ¥è¯†")
        
        # 1. é€‰æ‹©æˆ–è¾“å…¥çŸ¥è¯†åº“åç§°
        kb_action = st.radio("æ“ä½œæ¨¡å¼", ["è¿½åŠ åˆ°ç°æœ‰", "æ–°å»ºçŸ¥è¯†åº“"], horizontal=True)
        
        target_kb_name = ""
        if kb_action == "è¿½åŠ åˆ°ç°æœ‰":
            if existing_kbs:
                target_kb_name = st.selectbox("é€‰æ‹©çŸ¥è¯†åº“", existing_kbs)
            else:
                st.warning("è¯·å…ˆæ–°å»ºçŸ¥è¯†åº“")
        else:
            target_kb_name = st.text_input("è¾“å…¥æ–°çŸ¥è¯†åº“åç§° (è‹±æ–‡/æ•°å­—)", placeholder="example_kb")

        # === æ–°å¢ï¼šé€‰æ‹©çŸ¥è¯†åº“è¯­è¨€ ===
        kb_language = st.selectbox(
            "é€‰æ‹©æ–‡æ¡£ä¸»è¦è¯­è¨€ (ç”¨äºä¼˜åŒ–æ£€ç´¢)",
            ["Chinese", "English", "Japanese", "Korean", "French"],
            index=0,
            help="DeepSeek ä¼šå°†æœç´¢è¯è‡ªåŠ¨è½¬æ¢ä¸ºæ­¤è¯­è¨€ï¼Œæé«˜æ£€ç´¢å‡†ç¡®ç‡ã€‚"
        )
        # ===========================

        # 2. ä¸Šä¼ æ–‡ä»¶æˆ–æ–‡æœ¬
        upload_mode = st.tabs(["ğŸ“ ä¸Šä¼ æ–‡ä»¶", "ğŸ“ ç²˜è´´æ–‡æœ¬"])
        raw_docs = []
        
        with upload_mode[0]:
            uploaded_files = st.file_uploader("ä¸Šä¼  PDF/TXT", type=["pdf", "txt"], accept_multiple_files=True)
        
        with upload_mode[1]:
            text_input = st.text_area("è¾“å…¥é•¿æ–‡æœ¬", height=150)

        # 3. æäº¤æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜åˆ°çŸ¥è¯†åº“", use_container_width=True, key="save_kb_btn"):
            if not target_kb_name:
                st.error("çŸ¥è¯†åº“åç§°ä¸èƒ½ä¸ºç©ºï¼")
                return
                
            with st.spinner("æ­£åœ¨å¤„ç†..."):
                # å¤„ç†æ–‡ä»¶
                if uploaded_files:
                    for f in uploaded_files:
                        raw_docs.extend(load_file(f))
                
                # å¤„ç†æ–‡æœ¬
                if text_input:
                    raw_docs.append(Document(page_content=text_input, metadata={"source": "text_input"}))
                
                if not raw_docs:
                    st.warning("æ²¡æœ‰æ£€æµ‹åˆ°è¾“å…¥å†…å®¹ã€‚")
                    return

                # åˆ‡åˆ†å¹¶ä¿å­˜
                chunks = split_documents(raw_docs)
                
                # === ä¿®æ”¹ï¼šä¼ å…¥ selected language ===
                save_kb(target_kb_name, chunks, language=kb_language)
                # ==================================
                
                st.success(f"æˆåŠŸå°† {len(chunks)} ä¸ªç‰‡æ®µå­˜å…¥çŸ¥è¯†åº“: [{target_kb_name}] (è¯­è¨€: {kb_language})")
                st.rerun()


def render_chat():
    """èŠå¤©ç•Œé¢åŠå¤„ç†é€»è¾‘ã€‚"""
    
    # --- ä¾§è¾¹æ ï¼šåœ¨èŠå¤©æ¨¡å¼ä¸‹æ˜¾ç¤ºçŸ¥è¯†åº“é€‰æ‹© ---
    # æ³¨æ„ï¼šStreamlit ä¼šæŒ‰é¡ºåºåœ¨ Sidebar è¿½åŠ å†…å®¹
    with st.sidebar:
        st.divider()
        st.subheader("ğŸ§  çŸ¥è¯†åº“é€‰æ‹©")
        all_kbs = list_kbs()
        selected_kbs = st.multiselect(
            "é€‰æ‹©è¦æ£€ç´¢çš„çŸ¥è¯†åº“", 
            all_kbs,
            default=all_kbs[0] if all_kbs else None
        )
        
        if not selected_kbs:
            st.warning("âš ï¸ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªçŸ¥è¯†åº“")
        else:
            st.success(f"å·²åŠ è½½ {len(selected_kbs)} ä¸ªåº“")
            
        st.session_state.selected_kbs = selected_kbs

    # --- ä¸»åŒºåŸŸï¼šèŠå¤©å†å² ---
    st.header("ğŸ’¬ æ™ºèƒ½é—®ç­”")

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # --- åº•éƒ¨ï¼šèŠå¤©è¾“å…¥æ¡† ---
    # è¿™é‡Œ st.chat_input æ˜¯åœ¨ä¸»å±‚çº§è°ƒç”¨çš„ï¼Œæ²¡æœ‰åµŒå¥—åœ¨ Tabs é‡Œï¼Œå› æ­¤ä¸ä¼šæŠ¥é”™
    user_input = st.chat_input("è¯·è¾“å…¥é—®é¢˜...", key="chat_input")
    
    if user_input:
        selected_kbs = st.session_state.get("selected_kbs", [])
        
        if not selected_kbs:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ é€‰æ‹©çŸ¥è¯†åº“ï¼")
            return

        # 1. åŠ è½½é€‰ä¸­çš„çŸ¥è¯†åº“æ–‡æ¡£åˆ°å†…å­˜
        with st.spinner("æ­£åœ¨åŠ è½½çŸ¥è¯†åº“ç´¢å¼•..."):
            source_documents = load_kbs(selected_kbs)

        # 2. æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # 3. åˆå§‹åŒ– Graph è¾“å…¥
        # å°†å†å²æ¶ˆæ¯è½¬æ¢ä¸º LangChain æ ¼å¼ï¼Œä»¥ä¾¿ Agent æ‹¥æœ‰å¤šè½®å¯¹è¯è®°å¿†
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œåªä¼ å½“å‰é—®é¢˜ä½œä¸ºèµ·å§‹ï¼Œå¦‚æœéœ€è¦å¤šè½®è®°å¿†ï¼Œéœ€ä» session_state.messages è½¬æ¢
        initial_state = {
            "messages": [HumanMessage(content=user_input)],
            "source_documents": source_documents,
            "next": "Supervisor", # é»˜è®¤å…¥å£
            "current_search_query": ""
        }

        with st.chat_message("assistant"):
            # åˆ›å»ºä¸€ä¸ªå®¹å™¨ç”¨äºæ˜¾ç¤ºå®æ—¶çš„æ€è€ƒè¿‡ç¨‹
            status_container = st.status("Supervisor æ­£åœ¨è°ƒåº¦...", expanded=True)
            final_answer = ""

            try:
                # è¿è¡Œ Graph
                # stream_mode="updates" ä¼šè¿”å›æ¯ä¸ªèŠ‚ç‚¹æ›´æ–°çš„çŠ¶æ€
                for step in graph.stream(initial_state):
                    for node_name, update in step.items():
                        
                        # --- Supervisor èŠ‚ç‚¹ ---
                        if node_name == "Supervisor":
                            next_node = update.get("next")
                            query = update.get("current_search_query")
                            
                            if next_node == "Searcher":
                                status_container.write(f"ğŸ§  Supervisor å†³ç­–: æ´¾é£ Searcher å»æœç´¢ '{query}'")
                            elif next_node == "Answerer":
                                status_container.write(f"ğŸ§  Supervisor å†³ç­–: ä¿¡æ¯å·²è¶³å¤Ÿï¼Œæ´¾é£ Answerer ç”Ÿæˆæœ€ç»ˆå›ç­”")
                        
                        # --- Searcher èŠ‚ç‚¹ ---
                        elif node_name == "Searcher":
                            # Searcher è¿”å›çš„æ˜¯ AIMessage
                            if "messages" in update and update["messages"]:
                                msg = update["messages"][0]
                                if hasattr(msg, 'content'):
                                    content = msg.content
                                    status_container.write(f"ğŸ” Searcher æœç´¢ç»“æœ:")
                                    status_container.markdown(content)
                        
                        # --- Answerer èŠ‚ç‚¹ ---
                        elif node_name == "Answerer":
                            # Answerer è¿”å›çš„æ˜¯æœ€ç»ˆå›ç­”
                            if "messages" in update and update["messages"]:
                                msg = update["messages"][0]
                                if hasattr(msg, 'content'):
                                    final_answer = msg.content
                                    status_container.write("âœ… Answerer å·²ç”Ÿæˆæœ€ç»ˆå›ç­”")
                                    status_container.markdown(final_answer)
                        
                        # --- END ---
                        elif node_name == "__end__":
                            status_container.update(label="å›ç­”å®Œæˆ", state="complete", expanded=False)
                
                # æ˜¾ç¤ºæœ€ç»ˆå›ç­”
                if final_answer:
                    st.markdown(final_answer)
                    st.session_state.messages.append({"role": "assistant", "content": final_answer})
                else:
                    st.warning("æœªèƒ½ç”Ÿæˆå›ç­”ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚")
            
            except Exception as e:
                status_container.update(label="å‘ç”Ÿé”™è¯¯", state="error")
                st.error(f"è¿è¡Œé”™è¯¯: {e}")


def main():
    if not os.getenv("DEEPSEEK_API_KEY"):
        st.warning("è¯·é…ç½® .env æ–‡ä»¶ä¸­çš„ DEEPSEEK_API_KEY")

    # --- ä½¿ç”¨ä¾§è¾¹æ è¿›è¡Œé¡µé¢å¯¼èˆª ---
    with st.sidebar:
        st.title("DeepSeek RAG")
        page = st.radio(
            "åŠŸèƒ½å¯¼èˆª", 
            ["ğŸ’¬ å¯¹è¯æ¨¡å¼", "âš™ï¸ çŸ¥è¯†åº“ç®¡ç†"], 
            index=0
        )

    # æ ¹æ®é€‰æ‹©æ¸²æŸ“ä¸åŒçš„é¡µé¢ï¼ˆå‡½æ•°ï¼‰
    if page == "ğŸ’¬ å¯¹è¯æ¨¡å¼":
        render_chat()
    elif page == "âš™ï¸ çŸ¥è¯†åº“ç®¡ç†":
        render_kb_management()


if __name__ == "__main__":
    main()