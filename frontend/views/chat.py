# frontend/views/chat.py
import streamlit as st

# === ä¿®æ”¹å¼€å§‹ ===
# [åˆ é™¤] from src.graph import graph
# [æ–°å¢] å¼•ç”¨æ–°çš„ chat_graphï¼Œå¹¶é‡å‘½åä¸º graph ä»¥å…¼å®¹ä¸‹æ–¹ä»£ç 
from src.graphs.chat_graph import chat_graph as graph 
# === ä¿®æ”¹ç»“æŸ ===

from src.utils import load_file, split_documents
from src.storage import load_kbs, list_kbs # è¡¥å…¨ list_kbs
from src.db import init_db, create_session, get_all_sessions, get_messages, add_message, delete_session, update_session_title
from src.nodes.common import get_llm # ç¡®ä¿å¼•ç”¨è·¯å¾„æ­£ç¡®
from langchain_core.messages import HumanMessage, SystemMessage # è¡¥å…¨ SystemMessage
# === [ä¿®æ”¹] é€‚é… Langfuse v3 ===
try:
    from langfuse.langchain import CallbackHandler as LangfuseCallbackHandler
except ImportError:
    LangfuseCallbackHandler = None

# åˆå§‹åŒ–æ•°æ®åº“
init_db()

def render_history_sidebar():
    st.markdown("### ğŸ’¬ èŠå¤©å†å²")
    
    # æ–°å»ºå¯¹è¯æŒ‰é’®
    with st.container():
        st.markdown('<div class="new-chat-btn">', unsafe_allow_html=True)
        if st.button("â• å¼€å¯æ–°å¯¹è¯", use_container_width=True, type="primary"):
            new_id = create_session()
            st.session_state.current_session_id = new_id
            st.session_state.messages = []
            st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown("---")
    
    sessions = get_all_sessions()
    
    # è‡ªåŠ¨åŠ è½½é€»è¾‘
    if st.session_state.current_session_id is None:
        if sessions:
            st.session_state.current_session_id = sessions[0]['id']
            st.session_state.messages = get_messages(sessions[0]['id'])
        else:
            new_id = create_session()
            st.session_state.current_session_id = new_id
            st.session_state.messages = []
    
    # æ¸²æŸ“åˆ—è¡¨
    scroll_container = st.container(height=500, border=False)
    with scroll_container:
        for s in sessions:
            is_selected = (s['id'] == st.session_state.current_session_id)
            
            # ä½¿ç”¨åˆ—å¸ƒå±€ï¼šå·¦è¾¹æ˜¯æ ‡é¢˜æŒ‰é’®ï¼Œå³è¾¹æ˜¯åˆ é™¤æŒ‰é’®
            col1, col2 = st.columns([5, 1])
            
            with col1:
                # é€‰ä¸­çš„ä¼šè¯ä½¿ç”¨ primary æ ·å¼ï¼Œå…¶ä»–çš„ç”¨ secondary (CSS ä¼šå¤„ç†æˆé€æ˜èƒŒæ™¯)
                btn_type = "primary" if is_selected else "secondary"
                icon = "ğŸ“‚" if is_selected else "ğŸ—¨ï¸"
                
                if st.button(f"{icon} {s['title']}", key=f"sess_{s['id']}", use_container_width=True, type=btn_type):
                    st.session_state.current_session_id = s['id']
                    st.session_state.messages = get_messages(s['id'])
                    st.rerun()
            
            with col2:
                if st.button("ğŸ—‘ï¸", key=f"del_{s['id']}", help="åˆ é™¤æ­¤å¯¹è¯"):
                    delete_session(s['id'])
                    # å¦‚æœåˆ é™¤çš„æ˜¯å½“å‰ä¼šè¯ï¼Œé‡ç½®
                    if st.session_state.current_session_id == s['id']:
                        st.session_state.current_session_id = None
                        st.session_state.messages = []
                    st.rerun()

def generate_smart_title(query, answer):
    """ä½¿ç”¨ LLM ç”Ÿæˆç®€çŸ­çš„ä¼šè¯æ ‡é¢˜"""
    try:
        llm = get_llm()
        prompt = f"""
        è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªéå¸¸ç®€çŸ­çš„æ ‡é¢˜ï¼ˆ5-10ä¸ªå­—ä»¥å†…ï¼‰ï¼Œç”¨äºå†å²è®°å½•åˆ—è¡¨ã€‚
        ä¸è¦ä½¿ç”¨å¼•å·ï¼Œç›´æ¥è¾“å‡ºæ ‡é¢˜æ–‡æœ¬ã€‚
        
        ç”¨æˆ·: {query[:200]}
        AI: {answer[:200]}
        """
        response = llm.invoke([SystemMessage(content=prompt)])
        title = response.content.strip().replace('"', '').replace('ã€Š', '').replace('ã€‹', '')
        return title if len(title) < 15 else title[:15]
    except:
        return query[:10] + "..."

def format_display_message(content):
    split_markers = ["ã€ğŸ•µï¸â€â™‚ï¸ è°ƒæŸ¥ç¬”è®°ã€‘", "ã€ğŸ“š åŸå§‹ç‰‡æ®µã€‘", "ã€åŸå§‹çŸ¥è¯†åº“ç‰‡æ®µã€‘"]
    split_index = -1
    for marker in split_markers:
        idx = content.find(marker)
        if idx != -1:
            if split_index == -1 or idx < split_index:
                split_index = idx
    # ... (æ­¤å¤„çœç•¥å…·ä½“å®ç°ï¼Œä¿æŒä¸åŸæ–‡ä»¶ä¸€è‡´)

def render():
    with st.sidebar:
        st.subheader("ğŸ§  çŸ¥è¯†åº“é€‰æ‹©")
        all_kbs = list_kbs()
        selected_kbs = st.multiselect("é€‰æ‹©çŸ¥è¯†åº“", all_kbs, default=all_kbs[0] if all_kbs else None)
        st.session_state.selected_kbs = selected_kbs
        
        # æ¸²æŸ“å†å²è®°å½•
        render_history_sidebar()
    
    st.header("ğŸ’¬ DeepSeek Research Agent")
    
    # æ˜¾ç¤ºå½“å‰ä¼šè¯æ ‡é¢˜
    if st.session_state.current_session_id:
        sessions = get_all_sessions()
        current_session = next((s for s in sessions if s['id'] == st.session_state.current_session_id), None)
        if current_session:
            st.subheader(f"å½“å‰ä¼šè¯: {current_session['title']}")
    
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            if msg["role"] == "assistant":
                format_display_message(msg["content"])
            else:
                st.markdown(msg["content"])
    
    preset_query = st.session_state.next_query
    user_input = st.chat_input("è¯·è¾“å…¥é—®é¢˜...")
    
    final_query = None
    if user_input:
        final_query = user_input
        st.session_state.next_query = ""
    elif preset_query:
        final_query = preset_query
        st.session_state.next_query = ""
    
    if final_query:
        if not st.session_state.selected_kbs:
            st.error("è¯·é€‰æ‹©çŸ¥è¯†åº“ï¼")
            return
        
        with st.spinner("åŠ è½½ç´¢å¼•..."):
            source_documents, vector_store = load_kbs(st.session_state.selected_kbs)
        
        st.session_state.messages.append({"role": "user", "content": final_query})
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“
        if st.session_state.current_session_id:
            add_message(st.session_state.current_session_id, "user", final_query)
        
        with st.chat_message("user"):
            st.markdown(final_query)
        
        initial_state = {
            "messages": [HumanMessage(content=final_query)],
            "source_documents": source_documents,
            "vector_store": vector_store,
            "next": "Supervisor",
            "current_search_query": "",
            "final_evidence": [],
            "loop_count": 0,
            "attempted_searches": [],
            "research_notes": [],
            "failed_topics": [],
            # æ·±åº¦è§£è¯»ä¸“ç”¨å­—æ®µï¼ˆè®¾ç½®é»˜è®¤å€¼ï¼‰
            "full_content": "",
            "doc_title": "",
            "current_question": "",
            "qa_pairs": [],
            "final_report": ""
        }
        
        with st.chat_message("assistant"):
            status_container = st.status("ğŸ•µï¸â€â™‚ï¸ Agent æ­£åœ¨æ·±åº¦è°ƒç ”...", expanded=True)
            final_answer = ""
            
            try:
                # === [ä¿®æ”¹] é…ç½® Graph è¿è¡Œæ—¶å‚æ•° ===
                graph_config = {"recursion_limit": 50}
                
                # åªæœ‰å½“æ¨¡å—åŠ è½½æˆåŠŸä¸”æœ‰ session_id æ—¶æ‰é…ç½®
                if LangfuseCallbackHandler and st.session_state.current_session_id:
                    # 1. åˆå§‹åŒ– Handler (æ— å‚æ•°)
                    session_handler = LangfuseCallbackHandler()
                    
                    # 2. æ³¨å…¥ callbacks
                    graph_config["callbacks"] = [session_handler]
                    
                    # 3. [v3 é‡ç‚¹] é€šè¿‡ metadata ä¼ é€’ session_id
                    graph_config["metadata"] = {
                        "langfuse_session_id": st.session_state.current_session_id,
                        "langfuse_user_id": "user_admin" 
                    }
                
                # 3. ä¼ å…¥ config
                for step in graph.stream(initial_state, config=graph_config):
                    for node_name, update in step.items():
                        if node_name == "Supervisor":
                            next_node = update.get("next")
                            query = update.get("current_search_query")
                            loop = update.get("loop_count", 0)
                            if next_node == "Searcher":
                                status_container.write(f"ğŸ”„ **ç¬¬ {loop} è½®è°ƒç ”**: å‘ç°ç¼ºå£ï¼ŒæŒ‡æ´¾æœç´¢ `{query}`")
                            elif next_node == "Answerer":
                                status_container.write("âœ… **å†³ç­–**: ä¿¡æ¯å……è¶³ï¼Œæ­£åœ¨æ’°å†™æŠ¥å‘Š...")
                        elif node_name == "Searcher":
                            msgs = update.get("messages", [])
                            if msgs:
                                with status_container.expander(f"ğŸ” æ£€ç´¢æŠ¥å‘Š: {update.get('attempted_searches', [''])[0]}", expanded=False):
                                    st.markdown(msgs[-1].content)
                        elif node_name == "Answerer":
                            msgs = update.get("messages", [])
                            if msgs:
                                final_answer = msgs[-1].content
                
                status_container.update(label="å›ç­”å®Œæˆ", state="complete", expanded=False)
                
                if final_answer:
                    # ä¿å­˜åˆ°å†å²
                    st.session_state.messages.append({"role": "assistant", "content": final_answer})
                    # ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯åˆ°æ•°æ®åº“
                    if st.session_state.current_session_id:
                        add_message(st.session_state.current_session_id, "assistant", final_answer)
                    
                    # ç”Ÿæˆæ™ºèƒ½æ ‡é¢˜ï¼ˆä»…åœ¨ç¬¬ä¸€è½®å¯¹è¯åï¼‰
                    if st.session_state.current_session_id and len(st.session_state.messages) == 2:
                        smart_title = generate_smart_title(final_query, final_answer)
                        update_session_title(st.session_state.current_session_id, smart_title)
                        # æ›´æ–°ç•Œé¢æ˜¾ç¤º
                        st.rerun()
                    
                    # æ¸²æŸ“å½“å‰å›ç­” (ä½¿ç”¨ä¼˜åŒ–åçš„æ ¼å¼åŒ–å‡½æ•°)
                    format_display_message(final_answer)
            
            except Exception as e:
                status_container.update(label="Error", state="error")
                st.error(f"è¿è¡Œé”™è¯¯: {e}")