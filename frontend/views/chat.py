# frontend/views/chat.py
import streamlit as st

# === ä¿®æ”¹å¼€å§‹ ===
# [åˆ é™¤] from src.graph import graph
# [æ–°å¢] å¼•ç”¨æ–°çš„ chat_graphï¼Œå¹¶é‡å‘½åä¸º graph ä»¥å…¼å®¹ä¸‹æ–¹ä»£ç 
from src.graphs.chat_graph import chat_graph as graph 
# === ä¿®æ”¹ç»“æŸ ===

from src.utils import load_file, split_documents
from src.storage import load_kbs, list_kbs # è¡¥å…¨ list_kbs
from src.db import init_db, create_session, get_all_sessions, get_messages, add_message, delete_session, update_session_title
from src.nodes.common import get_llm # ç¡®ä¿å¼•ç”¨è·¯å¾„æ­£ç¡®
from langchain_core.messages import HumanMessage, SystemMessage # è¡¥å…¨ SystemMessage
from src.logger import get_logger

logger = get_logger("View_Chat")

# åˆå§‹åŒ–æ•°æ®åº“
init_db()

def render_history_sidebar():
    st.markdown("### ğŸ’¬ èŠå¤©å†å²")
    
    # æ–°å»ºå¯¹è¯æŒ‰é’®
    with st.container():
        st.markdown('<div class="new-chat-btn">', unsafe_allow_html=True)
        if st.button("â• å¼€å¯æ–°å¯¹è¯", use_container_width=True, type="primary"):
            new_id = create_session()
            st.session_state.current_session_id = new_id
            st.session_state.messages = []
            st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown("---")
    
    sessions = get_all_sessions()
    
    # è‡ªåŠ¨åŠ è½½é€»è¾‘
    if st.session_state.current_session_id is None:
        if sessions:
            st.session_state.current_session_id = sessions[0]['id']
            st.session_state.messages = get_messages(sessions[0]['id'])
        else:
            new_id = create_session()
            st.session_state.current_session_id = new_id
            st.session_state.messages = []
    
    # æ¸²æŸ“åˆ—è¡¨
    scroll_container = st.container(height=500, border=False)
    with scroll_container:
        for s in sessions:
            is_selected = (s['id'] == st.session_state.current_session_id)
            
            # ä½¿ç”¨åˆ—å¸ƒå±€ï¼šå·¦è¾¹æ˜¯æ ‡é¢˜æŒ‰é’®ï¼Œå³è¾¹æ˜¯åˆ é™¤æŒ‰é’®
            col1, col2 = st.columns([5, 1])
            
            with col1:
                # é€‰ä¸­çš„ä¼šè¯ä½¿ç”¨ primary æ ·å¼ï¼Œå…¶ä»–çš„ç”¨ secondary (CSS ä¼šå¤„ç†æˆé€æ˜èƒŒæ™¯)
                btn_type = "primary" if is_selected else "secondary"
                icon = "ğŸ“‚" if is_selected else "ğŸ—¨ï¸"
                
                if st.button(f"{icon} {s['title']}", key=f"sess_{s['id']}", use_container_width=True, type=btn_type):
                    st.session_state.current_session_id = s['id']
                    st.session_state.messages = get_messages(s['id'])
                    st.rerun()
            
            with col2:
                if st.button("ğŸ—‘ï¸", key=f"del_{s['id']}", help="åˆ é™¤æ­¤å¯¹è¯"):
                    delete_session(s['id'])
                    # å¦‚æœåˆ é™¤çš„æ˜¯å½“å‰ä¼šè¯ï¼Œé‡ç½®
                    if st.session_state.current_session_id == s['id']:
                        st.session_state.current_session_id = None
                        st.session_state.messages = []
                    st.rerun()

def generate_smart_title(query, answer):
    """ä½¿ç”¨ LLM ç”Ÿæˆç®€çŸ­çš„ä¼šè¯æ ‡é¢˜"""
    try:
        llm = get_llm()
        prompt = f"""
        è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªéå¸¸ç®€çŸ­çš„æ ‡é¢˜ï¼ˆ5-10ä¸ªå­—ä»¥å†…ï¼‰ï¼Œç”¨äºå†å²è®°å½•åˆ—è¡¨ã€‚
        ä¸è¦ä½¿ç”¨å¼•å·ï¼Œç›´æ¥è¾“å‡ºæ ‡é¢˜æ–‡æœ¬ã€‚
        
        ç”¨æˆ·: {query[:200]}
        AI: {answer[:200]}
        """
        response = llm.invoke([SystemMessage(content=prompt)])
        title = response.content.strip().replace('"', '').replace('ã€Š', '').replace('ã€‹', '')
        return title if len(title) < 15 else title[:15]
    except:
        return query[:10] + "..."

def format_display_message(content):
    """
    æ ¼å¼åŒ–æ˜¾ç¤ºæ¶ˆæ¯ï¼šå°†æ­£æ–‡ç›´æ¥æ˜¾ç¤ºï¼Œå°†å¼•ç”¨/ç¬”è®°æ”¾å…¥æŠ˜å æ¡†
    """
    # å®šä¹‰åˆ†éš”ç¬¦
    split_markers = ["ã€ğŸ•µï¸â€â™‚ï¸ è°ƒæŸ¥ç¬”è®°ã€‘", "ã€ğŸ“š åŸå§‹ç‰‡æ®µã€‘", "ã€åŸå§‹çŸ¥è¯†åº“ç‰‡æ®µã€‘", "<details>"]
    
    split_index = -1
    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå‡ºç°çš„åˆ†éš”ç¬¦ä½ç½®
    for marker in split_markers:
        idx = content.find(marker)
        if idx != -1:
            if split_index == -1 or idx < split_index:
                split_index = idx
    
    if split_index != -1:
        # åˆ†å‰²æ­£æ–‡å’Œé™„å½•
        main_text = content[:split_index].strip()
        references = content[split_index:].strip()
        
        # 1. æ˜¾ç¤ºæ­£æ–‡
        if main_text:
            st.markdown(main_text)
        else:
            # æç«¯æƒ…å†µï¼šåªæœ‰å¼•ç”¨æ²¡æœ‰æ­£æ–‡
            st.markdown("ï¼ˆåŸºäºä»¥ä¸‹å‚è€ƒèµ„æ–™ç”Ÿæˆï¼‰")

        # 2. æ˜¾ç¤ºæŠ˜å çš„é™„å½•
        with st.expander("ğŸ“š æŸ¥çœ‹å¼•ç”¨ä¸æ€è€ƒè¿‡ç¨‹ (Reference & Logs)", expanded=False):
            st.markdown(references, unsafe_allow_html=True)
    else:
        # æ²¡æœ‰åˆ†éš”ç¬¦ï¼Œç›´æ¥å…¨éƒ¨æ˜¾ç¤º
        st.markdown(content)

def render():
    with st.sidebar:
        st.subheader("ğŸ§  çŸ¥è¯†åº“é€‰æ‹©")
        all_kbs = list_kbs()
        selected_kbs = st.multiselect("é€‰æ‹©çŸ¥è¯†åº“", all_kbs, default=all_kbs[0] if all_kbs else None)
        st.session_state.selected_kbs = selected_kbs
        
        # æ¸²æŸ“å†å²è®°å½•
        render_history_sidebar()
    
    st.header("ğŸ’¬ DeepSeek Research Agent")
    
    # æ˜¾ç¤ºå½“å‰ä¼šè¯æ ‡é¢˜
    if st.session_state.current_session_id:
        sessions = get_all_sessions()
        current_session = next((s for s in sessions if s['id'] == st.session_state.current_session_id), None)
        if current_session:
            st.subheader(f"å½“å‰ä¼šè¯: {current_session['title']}")
    
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            if msg["role"] == "assistant":
                format_display_message(msg["content"])
            else:
                st.markdown(msg["content"])
    
    preset_query = st.session_state.next_query
    user_input = st.chat_input("è¯·è¾“å…¥é—®é¢˜...")
    
    final_query = None
    if user_input:
        final_query = user_input
        st.session_state.next_query = ""
    elif preset_query:
        final_query = preset_query
        st.session_state.next_query = ""
    
    if final_query:
        logger.info(f" >>> æ”¶åˆ°ç”¨æˆ·è¾“å…¥: {final_query} <<<")
        
        if not st.session_state.selected_kbs:
            logger.warning("ç”¨æˆ·æœªé€‰æ‹©çŸ¥è¯†åº“ï¼Œæ“ä½œä¸­æ­¢")
            st.error("è¯·é€‰æ‹©çŸ¥è¯†åº“ï¼")
            return
        
        with st.spinner("åŠ è½½ç´¢å¼•..."):
            try:
                source_documents, vector_store = load_kbs(st.session_state.selected_kbs)
                logger.info(f"çŸ¥è¯†åº“åŠ è½½æˆåŠŸ: {st.session_state.selected_kbs}")
            except Exception as e:
                logger.error(f"çŸ¥è¯†åº“åŠ è½½å¤±è´¥: {e}", exc_info=True)
                st.error("çŸ¥è¯†åº“åŠ è½½å‡ºé”™")
                return
        
        st.session_state.messages.append({"role": "user", "content": final_query})
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“
        if st.session_state.current_session_id:
            add_message(st.session_state.current_session_id, "user", final_query)
        
        with st.chat_message("user"):
            st.markdown(final_query)
        
        initial_state = {
            "messages": [HumanMessage(content=final_query)],
            "source_documents": source_documents,
            "vector_store": vector_store,
            "kb_names": st.session_state.selected_kbs,  # [æ–°å¢] ä¼ é€’çŸ¥è¯†åº“åç§°åˆ—è¡¨
            "next": "Supervisor",
            "current_search_query": "",
            "final_evidence": [],
            "loop_count": 0,
            "attempted_searches": [],
            "research_notes": [],
            "failed_topics": [],
            # [æ–°å¢] åˆå§‹åŒ–ä¸ºç©ºæˆ–é€šç”¨æè¿°
            "kb_summary": "æš‚æ—¶æœªçŸ¥ï¼ˆç­‰å¾…æ£€ç´¢ååˆ†æï¼‰",
            # æ·±åº¦è§£è¯»ä¸“ç”¨å­—æ®µï¼ˆè®¾ç½®é»˜è®¤å€¼ï¼‰
            "full_content": "",
            "doc_title": "",
            "current_question": "",
            "qa_pairs": [],
            "final_report": ""
        }
        
        with st.chat_message("assistant"):
            status_container = st.status("ğŸ•µï¸â€â™‚ï¸ Agent æ­£åœ¨æ·±åº¦è°ƒç ”...", expanded=True)
            final_answer = ""
            
            try:
                logger.info("å¼€å§‹æ‰§è¡Œ Graph Stream...")
                graph_config = {"recursion_limit": 50}
                for step in graph.stream(initial_state, config=graph_config):
                    for node_name, update in step.items():
                        # [Log] è®°å½•æµå¼æ­¥éª¤
                        logger.debug(f"Graph æ›´æ–° - èŠ‚ç‚¹: {node_name}")
                        
                        if node_name == "Supervisor":
                            next_node = update.get("next")
                            query = update.get("current_search_query")
                            loop = update.get("loop_count", 0)
                            if next_node == "Searcher":
                                status_container.write(f"ğŸ”„ **ç¬¬ {loop} è½®è°ƒç ”**: å‘ç°ç¼ºå£ï¼ŒæŒ‡æ´¾æœç´¢ `{query}`")
                            elif next_node == "Answerer":
                                status_container.write("âœ… **å†³ç­–**: ä¿¡æ¯å……è¶³ï¼Œæ­£åœ¨æ’°å†™æŠ¥å‘Š...")
                        elif node_name == "Searcher":
                            msgs = update.get("messages", [])
                            if msgs:
                                with status_container.expander(f"ğŸ” æ£€ç´¢æŠ¥å‘Š: {update.get('attempted_searches', [''])[0]}", expanded=False):
                                    st.markdown(msgs[-1].content)
                        elif node_name == "Answerer":
                            msgs = update.get("messages", [])
                            if msgs:
                                final_answer = msgs[-1].content
                                logger.info("è·å¾— Answerer æœ€ç»ˆå›å¤")
                
                status_container.update(label="å›ç­”å®Œæˆ", state="complete", expanded=False)
                
                if final_answer:
                    # 1. å…ˆä¿å­˜åˆ° State å’Œ DB
                    st.session_state.messages.append({"role": "assistant", "content": final_answer})
                    if st.session_state.current_session_id:
                        add_message(st.session_state.current_session_id, "assistant", final_answer)
                    
                    # 2. ã€å…³é”®ä¿®æ”¹ã€‘ç«‹å³æ¸²æŸ“å½“å‰å›ç­”ï¼ç¡®ä¿ç”¨æˆ·å…ˆçœ‹åˆ°ç»“æœ
                    format_display_message(final_answer)
                    
                    # 3. æœ€åå¤„ç†æ™ºèƒ½æ ‡é¢˜å’Œåˆ·æ–° (ä»…åœ¨ç¬¬ä¸€è½®å¯¹è¯å)
                    if st.session_state.current_session_id and len(st.session_state.messages) == 2:
                        # å¯ä»¥åœ¨è¿™é‡ŒåŠ ä¸ª toast æç¤ºï¼Œä¼˜åŒ–ä½“éªŒ
                        st.toast("æ­£åœ¨ç”Ÿæˆä¼šè¯æ ‡é¢˜...")
                        smart_title = generate_smart_title(final_query, final_answer)
                        update_session_title(st.session_state.current_session_id, smart_title)
                        st.rerun()  # æ­¤æ—¶å†åˆ·æ–°ï¼Œå†…å®¹å·²ç»æ˜¾ç¤ºè¿‡äº†ï¼Œåˆ·æ–°åä¹Ÿä¼šä» History å†æ¬¡åŠ è½½
                else:
                    logger.warning("Graph æ‰§è¡Œå®Œæˆä½†æ²¡æœ‰ç”Ÿæˆ final_answer")
            
            except Exception as e:
                status_container.update(label="Error", state="error")
                logger.error(f"Graph è¿è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå´©æºƒ: {e}", exc_info=True)
                st.error(f"è¿è¡Œé”™è¯¯: {e}")