# frontend/views/kb_management.py
import streamlit as st
from src.storage import list_kbs, delete_kb, get_kb_details, save_kb
from src.utils import load_file, split_documents
from langchain_core.documents import Document

def render():
    st.header("ğŸ“‚ çŸ¥è¯†åº“ç®¡ç†")
    tabs = st.tabs(["ğŸ“š çŸ¥è¯†åº“åˆ—è¡¨ & æ£€è§†", "â• æ–°å»º/è¿½åŠ çŸ¥è¯†"])
    
    with tabs[0]:
        existing_kbs = list_kbs()
        if not existing_kbs:
            st.info("æš‚æ— çŸ¥è¯†åº“ã€‚")
        else:
            col_list, col_detail = st.columns([1, 2])
            with col_list:
                st.subheader("çŸ¥è¯†åº“åˆ—è¡¨")
                selected_kb_to_view = st.radio("é€‰æ‹©çŸ¥è¯†åº“æŸ¥çœ‹è¯¦æƒ…", existing_kbs)
                st.markdown("---")
                if st.button(f"ğŸ—‘ï¸ åˆ é™¤ {selected_kb_to_view}", type="primary"):
                    delete_kb(selected_kb_to_view)
                    st.success(f"å·²åˆ é™¤ {selected_kb_to_view}")
                    st.rerun()
            
            with col_detail:
                # è·å–å¢å¼ºåçš„è¯¦æƒ…
                details = get_kb_details(selected_kb_to_view)
                
                # === æ ‡é¢˜æ  + çŠ¶æ€å¾½ç«  ===
                st.subheader(f"ğŸ” æ£€è§†: {selected_kb_to_view}")
                
                status = details["health_status"]
                if status == "healthy":
                    st.success(f"âœ… çŠ¶æ€å¥åº· (å®Œæ•´åº¦ 100%)")
                elif status == "mismatch":
                    loss = details['doc_count'] - details['vector_count']
                    st.error(f"âš ï¸ æ•°æ®ä¸ä¸€è‡´ï¼ä¸¢å¤± {loss} ä¸ªå‘é‡ç‰‡æ®µ (å»ºè®®é‡æ–°ç”Ÿæˆ)")
                elif status == "corrupted":
                    st.error("âŒ ç´¢å¼•æ–‡ä»¶æŸåï¼Œæ— æ³•è¯»å–")
                else:
                    st.warning("âšª ç©ºçŸ¥è¯†åº“")

                # === æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯” ===
                m1, m2, m3 = st.columns(3)
                m1.metric("åŸå§‹ç‰‡æ®µ (JSON)", details["doc_count"])
                
                # å¦‚æœæ•°é‡ä¸ä¸€è‡´ï¼Œç”¨çº¢è‰²æ˜¾ç¤ºå‘é‡æ•°
                vec_label = "å‘é‡ç´¢å¼• (FAISS)"
                vec_val = details["vector_count"]
                if status == "mismatch":
                    delta_color = "inverse"  # æ˜¾ç¤ºçº¢è‰²ä¸‹é™ç®­å¤´
                    m2.metric(vec_label, vec_val, delta=f"{vec_val - details['doc_count']}", delta_color=delta_color)
                else:
                    m2.metric(vec_label, vec_val)

                m3.metric("æ€»å­—ç¬¦æ•°", f"{details['total_chars'] / 1000:.1f}k")
                
                st.divider()
                
                # === è°ƒè¯•ä¿¡æ¯ ===
                with st.expander("ğŸ“Š è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯", expanded=True):
                    st.write(f"**è¯­è¨€**: {', '.join(details['languages']) if details['languages'] else 'æœªæŒ‡å®š'}")
                    st.write(f"**å­˜å‚¨è·¯å¾„**: `storage/{selected_kb_to_view}_faiss/index.faiss`")
                    if status == "mismatch":
                        st.caption("ğŸ’¡ æç¤ºï¼š'åŸå§‹ç‰‡æ®µ'æ¥è‡ª JSON å¤‡ä»½ï¼Œ'å‘é‡ç´¢å¼•'æ¥è‡ªå®é™… FAISS æ•°æ®åº“ã€‚å¦‚æœä¸ä¸€è‡´ï¼Œè¯´æ˜åœ¨å‘é‡åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿäº†ä¸­æ–­æˆ–é”™è¯¯ã€‚")

                st.write("ğŸ“„ **å†…å®¹é¢„è§ˆ**")
                if details["preview"]:
                    for item in details["preview"]:
                        with st.container(border=True):
                            st.caption(f"æ¥æº: {item['source']}")
                            st.text(item['content'])
                else:
                    st.caption("æ— é¢„è§ˆå†…å®¹")
    
    with tabs[1]:
        st.subheader("ä¸Šä¼ æ–‡æ¡£")
        kb_action = st.radio("æ¨¡å¼", ["è¿½åŠ åˆ°ç°æœ‰", "æ–°å»ºçŸ¥è¯†åº“"], horizontal=True)
        target_kb_name = ""
        if kb_action == "è¿½åŠ åˆ°ç°æœ‰":
            if existing_kbs:
                target_kb_name = st.selectbox("é€‰æ‹©ç›®æ ‡åº“", existing_kbs)
            else:
                st.warning("è¯·å…ˆæ–°å»º")
        else:
            target_kb_name = st.text_input("æ–°åº“åç§° (è‹±æ–‡/æ•°å­—)", placeholder="kb_v1")
        kb_language = st.selectbox("æ–‡æ¡£ä¸»è¦è¯­è¨€", ["Chinese", "English"], index=0)
        
        upload_mode = st.tabs(["ğŸ“ ä¸Šä¼ æ–‡ä»¶", "ğŸ“ ç²˜è´´æ–‡æœ¬"])
        raw_docs = []
        with upload_mode[0]:
            uploaded_files = st.file_uploader("æ”¯æŒ PDF/TXT", type=["pdf", "txt"], accept_multiple_files=True)
        with upload_mode[1]:
            text_input = st.text_area("è¾“å…¥æ–‡æœ¬", height=150)
        
        if st.button("ğŸ’¾ å¼€å§‹å¤„ç†å¹¶ä¿å­˜", use_container_width=True):
            if not target_kb_name:
                st.error("è¯·è¾“å…¥åç§°")
                return
            if uploaded_files:
                for f in uploaded_files:
                    raw_docs.extend(load_file(f))
            if text_input:
                from langchain_core.documents import Document
                raw_docs.append(Document(page_content=text_input, metadata={"source": "text_input"}))
            if not raw_docs:
                st.warning("æ²¡æœ‰å†…å®¹å¯ä¿å­˜ã€‚")
                return
            chunks = split_documents(raw_docs, chunk_size=800)
            st.info(f"å·²åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªç‰‡æ®µ (Chunk Size=800)")
            progress_bar = st.progress(0, text="åˆå§‹åŒ–å‘é‡åŒ–...")
            try:
                save_kb(target_kb_name, chunks, language=kb_language, progress_bar=progress_bar)
                st.success("âœ… ä¿å­˜æˆåŠŸï¼")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")