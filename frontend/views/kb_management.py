# frontend/views/kb_management.py
import streamlit as st
from src.storage import list_kbs, delete_kb, get_kb_details, load_file, split_documents, save_kb
from langchain_core.documents import Document

def render():
    st.header("ğŸ“‚ çŸ¥è¯†åº“ç®¡ç†")
    tabs = st.tabs(["ğŸ“š çŸ¥è¯†åº“åˆ—è¡¨ & æ£€è§†", "â• æ–°å»º/è¿½åŠ çŸ¥è¯†"])
    
    with tabs[0]:
        existing_kbs = list_kbs()
        if not existing_kbs:
            st.info("æš‚æ— çŸ¥è¯†åº“ã€‚")
        else:
            col_list, col_detail = st.columns([1, 2])
            with col_list:
                st.subheader("çŸ¥è¯†åº“åˆ—è¡¨")
                selected_kb_to_view = st.radio("é€‰æ‹©çŸ¥è¯†åº“æŸ¥çœ‹è¯¦æƒ…", existing_kbs)
                st.markdown("---")
                if st.button(f"ğŸ—‘ï¸ åˆ é™¤ {selected_kb_to_view}", type="primary"):
                    delete_kb(selected_kb_to_view)
                    st.success(f"å·²åˆ é™¤ {selected_kb_to_view}")
                    st.rerun()
            
            with col_detail:
                st.subheader(f"ğŸ” æ£€è§†: {selected_kb_to_view}")
                details = get_kb_details(selected_kb_to_view)
                m1, m2 = st.columns(2)
                m1.metric("ç‰‡æ®µæ•°é‡", details["doc_count"])
                m2.metric("æ€»å­—ç¬¦æ•°", details["total_chars"])
                st.divider()
                st.write("ğŸ“„ **å†…å®¹é¢„è§ˆ (éšæœºå‰5æ¡)**")
                if details["preview"]:
                    for item in details["preview"]:
                        with st.container(border=True):
                            st.caption(f"æ¥æº: {item['source']}")
                            st.text(item['content'])
                else:
                    st.write("è¯¥çŸ¥è¯†åº“ä¸ºç©ºæˆ–æ— æ³•è¯»å–ã€‚")
    
    with tabs[1]:
        st.subheader("ä¸Šä¼ æ–‡æ¡£")
        kb_action = st.radio("æ¨¡å¼", ["è¿½åŠ åˆ°ç°æœ‰", "æ–°å»ºçŸ¥è¯†åº“"], horizontal=True)
        target_kb_name = ""
        if kb_action == "è¿½åŠ åˆ°ç°æœ‰":
            if existing_kbs:
                target_kb_name = st.selectbox("é€‰æ‹©ç›®æ ‡åº“", existing_kbs)
            else:
                st.warning("è¯·å…ˆæ–°å»º")
        else:
            target_kb_name = st.text_input("æ–°åº“åç§° (è‹±æ–‡/æ•°å­—)", placeholder="kb_v1")
        kb_language = st.selectbox("æ–‡æ¡£ä¸»è¦è¯­è¨€", ["Chinese", "English"], index=0)
        
        upload_mode = st.tabs(["ğŸ“ ä¸Šä¼ æ–‡ä»¶", "ğŸ“ ç²˜è´´æ–‡æœ¬"])
        raw_docs = []
        with upload_mode[0]:
            uploaded_files = st.file_uploader("æ”¯æŒ PDF/TXT", type=["pdf", "txt"], accept_multiple_files=True)
        with upload_mode[1]:
            text_input = st.text_area("è¾“å…¥æ–‡æœ¬", height=150)
        
        if st.button("ğŸ’¾ å¼€å§‹å¤„ç†å¹¶ä¿å­˜", use_container_width=True):
            if not target_kb_name:
                st.error("è¯·è¾“å…¥åç§°")
                return
            if uploaded_files:
                for f in uploaded_files:
                    raw_docs.extend(load_file(f))
            if text_input:
                from langchain_core.documents import Document
                raw_docs.append(Document(page_content=text_input, metadata={"source": "text_input"}))
            if not raw_docs:
                st.warning("æ²¡æœ‰å†…å®¹å¯ä¿å­˜ã€‚")
                return
            chunks = split_documents(raw_docs, chunk_size=800)
            st.info(f"å·²åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªç‰‡æ®µ (Chunk Size=800)")
            progress_bar = st.progress(0, text="åˆå§‹åŒ–å‘é‡åŒ–...")
            try:
                save_kb(target_kb_name, chunks, language=kb_language, progress_bar=progress_bar)
                st.success("âœ… ä¿å­˜æˆåŠŸï¼")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")